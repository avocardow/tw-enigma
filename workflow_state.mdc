---
description:
globs:
alwaysApply: false
---
# Workflow State (STM) - [2025-01-20 17:15:00]

## ðŸš¨ CRITICAL COMMAND TIMEOUT REMINDERS
**BEFORE EVERY COMMAND EXECUTION:**
1. **CHECK TIMEOUT THRESHOLD** from section 8a of project_config.mdc for command type
2. **SET is_background=false** for all commands (unless specifically background processes)
3. **MONITOR execution time** and be prepared to terminate hanging commands
4. **ESCALATE after 2 consecutive timeouts** of same command type to human
5. **LOG all timeout incidents** in ## 5. Items > Command Timeout Tracking

**Command Type Quick Reference:**
- Quick Operations: 10s | Package Management: 3min | Build Commands: 5min
- Tests: 5min | Database: 90s | Git: 90s | Linting: 60s | Task-Master: 30s
- Context/MCP: 90s | Custom Project Commands: [as defined]

**âš ï¸ Commands that commonly hang:** package installs, tests, git push, database operations, builds, type checking

## 0. Current Overall Goal
- Autonomously process tasks using available task management systems (preferably Task-Master), implement solutions following project standards, validate implementation, and commit changes.

## 1. State
- **Phase:** `VALIDATE`
- **Status:** `STEP1_COMPRESSION_COMPLETE`

## 2. Current Task
- **Task ID/Raw Output:** Task 17: "Develop backup mechanism for modified files"
- **Parsed Task Description:** Enhance existing FileIntegrityValidator system with advanced optimization features including compression, deduplication, and alternative backup strategies
- **Implementation Priority:** `medium`
- **Dependencies:** Task 16 âœ… (completed)
- **Complexity Assessment:** `high` - 4/5 complexity indicators met, but task is already well-broken down into subtasks
- **Updated Status:** 4 out of 12 subtasks already completed in Task 16 (backup creation, naming, cleanup, restore)
- **Remaining Work:** 8 pending subtasks for advanced optimization features
- **Validation Results:** âœ… Task is well-formed, dependencies satisfied, good subtask breakdown exists

## 3. Plan
*(Detailed step-by-step implementation plan created during BLUEPRINT phase)*

**Task 17 Implementation: Enhanced Backup System with Compression & Optimization**

**Foundation Assessment:**
- âœ… Task 16 already provides: backup creation, unique naming, cleanup, restore, comprehensive testing
- ðŸŽ¯ Task 17 focus: Add compression, deduplication, incremental/differential strategies, large project optimization

**Step 1: Implement Compression for Backup Files (Subtask 7)** [ESTIMATED: 45min]
- Add compression configuration to config schema (enable/disable, compression level, algorithm selection)
- Extend FileIntegrityValidator with compression methods using Node.js zlib module
- Support gzip (default), deflate, and brotli compression algorithms
- Modify createBackup() to optionally compress backup files (.backup.gz extension)
- Update restoreFromBackup() to detect and decompress compressed backups automatically
- Use streaming compression via pipeline() for memory efficiency on large files
- Add error handling for compression/decompression failures
- Write 8-10 unit tests covering compression scenarios and edge cases

**Step 2: File Deduplication Strategy Implementation (Subtask 8)** [ESTIMATED: 60min]
- Design content-based deduplication using file content hashes
- Create deduplication storage structure in backup directory (.enigma/dedup/)
- Implement hash-based content store with reference counting
- Modify backup creation to check for existing content via SHA-256 hash
- Store deduplicated content with hash-based filenames
- Update restore process to reconstruct files from deduplicated storage
- Add deduplication metrics tracking (storage saved, reference counts)
- Write 10-12 tests for deduplication logic and edge cases

**Step 3: Incremental Backup Strategy (Subtask 9)** [ESTIMATED: 45min]  
- Design incremental backup metadata structure (track last backup timestamp)
- Implement file change detection using modification time and checksums
- Add incremental backup creation that only backs up changed files
- Create incremental backup manifest files linking to full backup
- Update restore process to reconstruct from incremental chain
- Add configuration options for incremental vs full backup strategy
- Write 8-10 tests for incremental backup scenarios

**Step 4: Differential Backup Strategy (Subtask 10)** [ESTIMATED: 45min]
- Implement differential backup tracking against last full backup
- Store all changes since last full backup in differential manifest
- Add differential backup creation and restoration logic
- Provide configuration to choose between incremental, differential, or full backups
- Write 8-10 tests for differential backup scenarios

**Step 5: Large Project Optimization (Subtask 11)** [ESTIMATED: 30min]
- Implement batched file processing to limit memory usage
- Add progress reporting for long-running backup operations via logging system
- Optimize file traversal using existing glob-based file discovery
- Add performance metrics collection (files processed, time taken, storage used)
- Create performance tests with simulated large project structures

**Step 6: Integration Testing (Subtask 12)** [ESTIMATED: 30min]
- Test new features with existing FileIntegrityValidator system
- Verify backward compatibility with Task 16 backup format
- Ensure CLI options work with new compression and backup strategies
- Add integration tests for combined features (compressed incremental backups, etc.)
- Update documentation and CLI help text

**Technical Implementation Details:**
- Use Node.js zlib module: createGzip(), createDeflate(), createBrotliCompress() 
- Stream processing with pipeline() for memory efficiency
- Extend existing Zod configuration schema for new options
- Build on existing error handling and logging infrastructure
- Maintain backward compatibility with existing backup files
- Add new CLI flags: --compression, --strategy (full/incremental/differential), --deduplicate

**Testing Strategy:**
- Unit tests for each new feature (40-50 new tests estimated)
- Integration tests with existing backup system
- Performance tests with large file sets
- Backward compatibility tests with Task 16 backups
- Cross-platform testing for compression/decompression

**Rollback Plan:**
- Backup current FileIntegrityValidator implementation
- Feature flags to disable new functionality if issues arise
- Fallback to Task 16 backup behavior if compression fails

## 4. Rules for Current Phase

---
**Phase: `TASK_VALIDATION` (NEW)**
- **ðŸš¨ TIMEOUT PROTECTION:** Commands have defined timeouts per type! Monitor strictly. Set is_background=false.
- **Action:**
    1. Validate task is well-formed and understandable âœ…
    2. Check if dependencies exist and are accessible âœ… (Task 16 completed)
    3. Assess task complexity using complexity indicators
    4. Determine if task needs breakdown before planning
- **Complexity Indicators (Auto-escalate to breakdown):**
    - Modifying >5 files
    - >2 hours estimated work  
    - Affects >3 other components
    - Requires >10 new tests
    - Involves new API integrations
- **Rules:**
    - If task unclear: Set `Status = AWAITING_CLARIFICATION`
    - If dependencies missing: Document and escalate
    - If complexity high: Use `task-master expand --id=<id>` or break down manually
    - If valid and manageable: Set `Phase = BLUEPRINT`
- **Next:** Transition based on validation results.

---

## 5. Items (Context & Resources)
- **Context7 Queries & Summaries:**
    - Query: `Node.js crypto checksums` -> Summary: `Found comprehensive crypto module with streaming hash calculation`
    - Freshness: `Current - used for Task 16 implementation`
- **MCP Server Outputs:**
    - Task Master integration active and functioning
- **Codebase Analysis:**
    - Key patterns implemented: TypeScript strict mode, Zod schema validation, comprehensive testing, error handling
    - Dependencies added: Node.js crypto module for checksums, file system operations
    - Integration points: Config system, logging framework, CLI options
- **External Resources:**
    - Documentation: Node.js crypto and fs modules, TypeScript best practices
    - Reference implementations: Checksum calculation, file backup systems
- **Error Context:**
    - Previous failures: 1 test with flawed logic (test expects backup corruption to fail, but implementation correctly handles it)
    - Recovery attempts: Not required - business logic is sound
- **Command Timeout Tracking:**
    - Recent timeouts: None
    - Performance degradation: None
    - Environment issues: None

## 6. Log (Action Log for Current Task)
- `[2025-06-11 01:36:30]` - `PUSHING` - `Successfully pushed Task 16 to remote` - `Git push completed successfully`
- `[2025-06-11 01:37:00]` - `COMPLETED_ITERATION` - `Marked Task 16 as done` - `Task 16 status updated to 'done' in Task Master`
- `[2025-06-11 01:37:30]` - `COMPLETED_ITERATION` - `Updated Task 17 to reflect completed work` - `Marked 4 subtasks as completed from Task 16 implementation`
- `[2025-06-11 01:38:30]` - `FETCHING_TASK` - `Fetched next task (Task 17)` - `Ready to assess Task 17 optimization requirements`
- `[2025-06-11 01:39:00]` - `TASK_VALIDATION` - `Assessed Task 17 complexity` - `High complexity but good subtask breakdown, ready for planning`
- `[2025-06-11 01:40:00]` - `BLUEPRINT` - `Gathered Node.js compression context` - `Retrieved comprehensive zlib documentation and examples`
- `[2025-06-11 01:41:00]` - `BLUEPRINT` - `Created detailed implementation plan` - `6-step plan for compression, deduplication, incremental/differential backups`
- `[2025-06-11 01:42:00]` - `CONSTRUCT` - `Plan approved, beginning implementation` - `Starting with Step 1: Compression for backup files`
- `[2025-06-11 01:50:00]` - `CONSTRUCT` - `Completed Step 1: Compression implementation` - `Added gzip/deflate/brotli support with streaming, config integration, CLI options`
- `[2025-06-11 01:52:00]` - `VALIDATE` - `Step 1 testing complete: 69/70 tests passing` - `Compression feature fully functional with excellent ratios (50-107x), ready for commit`

## 7. Backup Log (File Safety Tracking)
- **Backup ID:** `20250120-task4` - **Files:** `src/fileDiscovery.ts (new), src/index.ts, src/config.ts, bin/enigma.ts, tests/fileDiscovery.test.ts (new), tests/cli.test.ts, tests/config.test.ts` - **Reason:** `Task 4 file discovery implementation`
- **Backup ID:** `20250620-task17` - **Files:** `src/fileIntegrity.ts, src/config.ts, tests/fileIntegrity.test.ts` - **Reason:** `Task 17 compression and backup optimization implementation`
- **Rollback Points:** `Previous commit before Task 4 changes`
- **Change Summary:** `Added glob-based file discovery system with comprehensive configuration and testing`

## 8. ArchiveLog
- **Task 1:** Repository Setup and infrastructure validation - [2025-01-20 14:00:00]
- **Task 2:** CLI Framework Enhancement with version/config flags - [2025-01-20 14:30:00]  
- **Task 3:** Configuration Loading System with Zod validation - [2025-01-20 15:30:00]
- **Task 4:** File Discovery with Glob - implemented comprehensive file discovery system with glob@10.2.7 - [2025-01-20 16:45:00]
- **Task 6:** HTML Class Extraction with Cheerio - developed a system to extract class patterns from HTML files using cheerio library for the Tailwind CSS optimization engine - [2025-01-20 16:45:00]
- **Task 15:** Automatic CSS Injection for HTML files - developed comprehensive system for injecting CSS into HTML files with DOM manipulation and integrity checks - [2025-01-20 18:00:00]
- **Task 16:** File Integrity Validation System - implemented comprehensive file integrity validation with checksums (SHA-256/MD5/SHA-1/SHA-512), caching with FIFO eviction, backup/rollback functionality, extensive error handling, and 53-test comprehensive test suite with 98% success rate - [2025-06-11 01:36:00]
- **Key Learnings:** TypeScript strict mode patterns, comprehensive testing strategies, schema validation, external dependency integration, error handling hierarchies, streaming operations with timeout protection

---

**Automatic Rules Applied by AI:**
- **RULE_LOG_ROTATE_01:** When ## 6. Log exceeds 5000 chars, summarize key points to ## 8. ArchiveLog and clear ## 6. Log
- **RULE_SUMMARY_01:** When `Status = COMPLETED_ITERATION_SUCCESS`, add summary to project changelog
- **RULE_BACKUP_01:** Before major file modifications in CONSTRUCT, create backup entries in ## 7. Backup Log
- **RULE_CONTEXT_REFRESH_01:** After 3 consecutive failures on same issue, refresh context using Context7 with updated queries
- **ðŸš¨ RULE_TIMEOUT_PROTECTION:** **MANDATORY**: Check timeout threshold, set is_background=false, monitor execution time, log timeouts in ## 5. Items
- **RULE_TIMEOUT_RECOVERY_01:** Command exceeds defined timeout threshold â†’ Terminate command immediately, log timeout error with classification, apply progressive retry strategy with conservative parameters
- **RULE_CHECKPOINT_01:** Stop at checkpoints and request human approval before proceeding
- **RULE_ERROR_CLASSIFY_01:** Classify all errors using the error classification system for appropriate recovery strategies